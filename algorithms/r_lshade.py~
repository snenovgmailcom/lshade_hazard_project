#!/usr/bin/env python3
"""
Pure classical L-SHADE (Tanabe & Fukunaga, 2014)

References:
    R. Tanabe and A. Fukunaga,
    "Improving the Search Performance of SHADE Using
     Linear Population Size Reduction",
    IEEE CEC 2014.

This implementation:
    - Follows Algorithm 2 (L-SHADE) exactly
    - Uses Lehmer mean for F (Eq. 7)
    - Uses weighted Lehmer mean for CR (Eq. 7)
    - Uses Linear Population Size Reduction (Eq. 10)
    - Uses midpoint bound handling (Eq. 4)
    - Uses PCG64 RNG for reproducibility
"""

import numpy as np
from scipy.stats import cauchy


class LSHADE:
    def __init__(
        self,
        func,
        bounds,
        popsize=None,
        N_min=4,
        max_evals=None,
        memory_size=6,
        sigma_f=0.1,
        sigma_cr=0.1,
        p_best_rate=0.11,
        arc_rate=2.6,
        atol=0.0,
        seed=None,
        disp=False,
    ):
        self.func = func
        self.bounds = np.array(bounds, float)
        self.dim = len(bounds)

        # Table II
        self.N_init = popsize if popsize is not None else 18 * self.dim
        self.N_min = N_min
        self.popsize = self.N_init

        # Eq. (10)
        self.max_evals = max_evals if max_evals is not None else 10000 * self.dim

        # Algorithm 1: parameter memories
        self.memory_size = memory_size
        self.memory_f = np.full(memory_size, 0.5)
        self.memory_cr = np.full(memory_size, 0.5, dtype=object)
        self.memory_pos = 0

        self.sigma_f = sigma_f
        self.sigma_cr = sigma_cr
        self.p_best_rate = p_best_rate
        self.arc_rate = arc_rate

        # Archive (Section II-D)
        self.archive_capacity = int(round(self.arc_rate * self.N_init))
        self.archive = []

        self.atol = atol
        self.disp = disp

        # RNG
        self.rng = np.random.Generator(np.random.PCG64(seed))

        # Counters
        self.nfev = 0
        self.nit = 0

        self.best_fitness = np.inf
        self.best_individual = None
        self.convergence = []

    # ------------------------------------------------------------
    # Algorithm 2, line 2: Initialize population
    # ------------------------------------------------------------
    def _initialize_population(self):
        lower = self.bounds[:, 0]
        upper = self.bounds[:, 1]
        return self.rng.uniform(lower, upper, (self.N_init, self.dim))

    # ------------------------------------------------------------
    # Eq. (10): Linear Population Size Reduction
    # ------------------------------------------------------------
    def _compute_target_pop_size(self):
        ratio = (self.max_evals - self.nfev) / self.max_evals
        ratio = np.clip(ratio, 0.0, 1.0)
        N_target = self.N_min + (self.N_init - self.N_min) * ratio
        return max(self.N_min, int(round(N_target)))

    # ------------------------------------------------------------
    # Algorithm 2, lines 21–24: Shrink population
    # ------------------------------------------------------------
    def _shrink_population(self, pop, fit):
        N_target = self._compute_target_pop_size()
        current = len(pop)

        if N_target < current:
            n_remove = current - N_target
            worst = np.argsort(fit)[-n_remove:]
            mask = np.ones(current, dtype=bool)
            mask[worst] = False
            pop = pop[mask]
            fit = fit[mask]

            self.archive_capacity = int(round(self.arc_rate * len(pop)))
            if len(self.archive) > self.archive_capacity:
                idx = self.rng.choice(len(self.archive), self.archive_capacity, replace=False)
                self.archive = [self.archive[i] for i in idx]

        return pop, fit

    # ------------------------------------------------------------
    # Eq. (4): Bound handling (midpoint)
    # ------------------------------------------------------------
    def _bound_constrain(self, mutant, parent):
        lower = self.bounds[:, 0]
        upper = self.bounds[:, 1]
        result = mutant.copy()

        for j in range(self.dim):
            if result[j] < lower[j]:
                result[j] = 0.5 * (lower[j] + parent[j])
            elif result[j] > upper[j]:
                result[j] = 0.5 * (upper[j] + parent[j])

        return result

    # ------------------------------------------------------------
    # Section II-D: External archive
    # ------------------------------------------------------------
    def _update_archive(self, individual):
        # Algorithm 2 / Section II-D: insert then, if needed, delete random entries
        self.archive.append(individual)
        if len(self.archive) > self.archive_capacity:
            idx = self.rng.integers(0, len(self.archive))
            del self.archive[idx]

    # ------------------------------------------------------------
    # Algorithm 1: Memory update (Eq. 7, 8, 9)
    # ------------------------------------------------------------
    def _update_memory(self, successful_f, successful_cr, delta_f):
        if len(successful_f) == 0:
            return

        k = self.memory_pos

        s_f = np.asarray(successful_f)
        s_cr = np.asarray(successful_cr)
        delta = np.asarray(delta_f)

        total_delta = delta.sum()
        if total_delta <= 0:
            return

        w = delta / total_delta  # Eq. (9)

        # Eq. (7)-(9): Lehmer mean for F
        mean_f = np.sum(w * (s_f ** 2)) / (np.sum(w * s_f) + 1e-12)
        mean_f = float(np.clip(mean_f, 0.0, 1.0))
        self.memory_f[k] = mean_f

        if self.memory_cr[k] is None or np.max(s_cr) == 0.0:
            self.memory_cr[k] = None  # terminal value ⊥
        else:
            # Eq. (7)-(9): weighted Lehmer mean for CR (meanWL)
            mean_cr = np.sum(w * (s_cr ** 2)) / (np.sum(w * s_cr) + 1e-12)
            self.memory_cr[k] = float(np.clip(mean_cr, 0.0, 1.0))

        self.memory_pos = (self.memory_pos + 1) % self.memory_size

    # ------------------------------------------------------------
    # One generation of L-SHADE
    # ------------------------------------------------------------
    def _lshade_generation(self, pop, fit):
        NP = len(pop)

        new_pop = []
        new_fit = []

        successful_f = []
        successful_cr = []
        delta_f = []

        for i in range(NP):
            if self.nfev >= self.max_evals:
                for j in range(i, NP):
                    new_pop.append(pop[j])
                    new_fit.append(fit[j])
                break

            r = self.rng.integers(0, self.memory_size)

            # Eq. (2): F ~ Cauchy
            while True:
                F = cauchy.rvs(
                    loc=self.memory_f[r],
                    scale=self.sigma_f,
                    random_state=self.rng,
                )
                if F > 1:
                    F = 1
                if F > 0:
                    break

            # Eq. (1): CR ~ Normal (randn) + boundary clipping
            mu = self.memory_cr[r]

            if mu is None:
                # terminal CR ⊥
                CR = 0.0
            else:
                CR = float(self.rng.normal(mu, self.sigma_cr))
                CR = float(np.clip(CR, 0.0, 1.0))

            # p-best selection
            p_num = max(2, int(np.ceil(self.p_best_rate * NP)))
            pbest_pool = np.argsort(fit)[:p_num]
            pbest_idx = self.rng.choice(pbest_pool)

            # r1
            r1 = self.rng.choice([j for j in range(NP) if j != i])

            # r2 from population ∪ archive
            total = NP + len(self.archive)
            candidates = [j for j in range(total) if j != i and j != r1]
            if not candidates:
                new_pop.append(pop[i])
                new_fit.append(fit[i])
                continue

            r2 = self.rng.choice(candidates)
            x_r2 = pop[r2] if r2 < NP else self.archive[r2 - NP]

            # Eq. (3): Mutation
            mutant = (
                pop[i]
                + F * (pop[pbest_idx] - pop[i])
                + F * (pop[r1] - x_r2)
            )

            mutant = self._bound_constrain(mutant, pop[i])

            # Eq. (5): Binomial crossover
            trial = pop[i].copy()
            j_rand = self.rng.integers(0, self.dim)
            for j in range(self.dim):
                if self.rng.random() < CR or j == j_rand:
                    trial[j] = mutant[j]

            f_trial = float(self.func(trial))
            self.nfev += 1

            # Eq. (6): Selection
            if f_trial <= fit[i]:
                new_pop.append(trial)
                new_fit.append(f_trial)

                if f_trial < fit[i]:
                    self._update_archive(pop[i].copy()) # Eq. (6)
                    successful_f.append(F)
                    successful_cr.append(CR)
                    delta_f.append(fit[i] - f_trial)
            else:
                new_pop.append(pop[i])
                new_fit.append(fit[i])

        self._update_memory(successful_f, successful_cr, delta_f)

        new_pop = np.asarray(new_pop)
        new_fit = np.asarray(new_fit)

        return self._shrink_population(new_pop, new_fit)

    # ------------------------------------------------------------
    # Main loop
    # ------------------------------------------------------------
    def solve(self):
        pop = self._initialize_population()
        fit = np.array([self.func(x) for x in pop])
        self.nfev += len(fit)

        best_idx = np.argmin(fit)
        self.best_fitness = float(fit[best_idx])
        self.best_individual = pop[best_idx].copy()
        self.convergence.append(self.best_fitness)

        if self.disp:
            print(f"Initial best = {self.best_fitness:.6e}")

        while self.nfev < self.max_evals:
            self.nit += 1
            pop, fit = self._lshade_generation(pop, fit)

            best_idx = np.argmin(fit)
            best_now = float(fit[best_idx])
            if best_now < self.best_fitness:
                self.best_fitness = best_now
                self.best_individual = pop[best_idx].copy()

            self.convergence.append(self.best_fitness)

            if self.atol > 0 and self.best_fitness <= self.atol:
                break

        return type(
            "Result",
            (),
            dict(
                x=self.best_individual,
                fun=self.best_fitness,
                nit=self.nit,
                nfev=self.nfev,
                convergence=self.convergence,
                final_pop_size=len(pop),
            ),
        )()
